{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuveljebakumar/fish/blob/main/Copy_of_today.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "dkqS6z_brd4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MmupLBVnDEZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/today\""
      ],
      "metadata": {
        "id": "dqMi3p6kZPlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mel_sequence(file_path):\n",
        "    y, sr = librosa.load(file_path, duration=5, mono=True)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "    # Convert to shape (time, features) for LSTM\n",
        "    mel_db = mel_db.T     # now shape = (time_frames, 128)\n",
        "\n",
        "    # Fix size (keep 300 frames)\n",
        "    if mel_db.shape[0] < 300:\n",
        "        pad_width = 300 - mel_db.shape[0]\n",
        "        mel_db = np.pad(mel_db, ((0, pad_width), (0,0)), mode='constant')\n",
        "    else:\n",
        "        mel_db = mel_db[:300, :]\n",
        "\n",
        "    return mel_db\n"
      ],
      "metadata": {
        "id": "EkKsKKDhULiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "# Add a check for DATASET_PATH existence\n",
        "if not os.path.isdir(DATASET_PATH):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Dataset path not found: '{DATASET_PATH}'. \"\n",
        "        \"Please ensure Google Drive is mounted and the path is correct.\"\n",
        "    )\n",
        "\n",
        "print(f\"Starting data loading from: {DATASET_PATH}\")\n",
        "found_files_count = 0\n",
        "found_labels_set = set() # To track actual labels found for files\n",
        "\n",
        "# First, gather all unique true labels (e.g., bird names) across all subdirectories\n",
        "unique_labels = set()\n",
        "for split_folder in os.listdir(DATASET_PATH):\n",
        "    split_path = os.path.join(DATASET_PATH, split_folder)\n",
        "    if os.path.isdir(split_path):\n",
        "        print(f\"  Found split folder: {split_folder}\")\n",
        "        if not os.listdir(split_path):\n",
        "            print(f\"    Warning: Split folder '{split_folder}' is empty.\")\n",
        "        for label_folder_name in os.listdir(split_path):\n",
        "            label_path = os.path.join(split_path, label_folder_name)\n",
        "            if os.path.isdir(label_path):\n",
        "                print(f\"    Found label folder: {label_folder_name}\")\n",
        "                unique_labels.add(label_folder_name)\n",
        "            else:\n",
        "                print(f\"    Skipping non-directory item in '{split_folder}': {label_folder_name}\")\n",
        "    else:\n",
        "        print(f\"  Skipping non-directory item in DATASET_PATH: {split_folder}\")\n",
        "\n",
        "# Sort labels to ensure consistent encoding\n",
        "sorted_unique_labels = sorted(list(unique_labels))\n",
        "print(f\"\\nUnique labels found (before filtering for actual files): {sorted_unique_labels}\")\n",
        "# The LabelEncoder will be applied in the next cell (0XaniC02UjC1)\n",
        "\n",
        "# Second pass to extract melspectrograms and associate with string labels\n",
        "for split_folder in os.listdir(DATASET_PATH):\n",
        "    split_path = os.path.join(DATASET_PATH, split_folder)\n",
        "    if os.path.isdir(split_path):\n",
        "        for label_folder_name in os.listdir(split_path):\n",
        "            label_folder_path = os.path.join(split_path, label_folder_name)\n",
        "            if os.path.isdir(label_folder_path):\n",
        "                if not os.listdir(label_folder_path):\n",
        "                    print(f\"      Warning: Label folder '{label_folder_name}' in '{split_folder}' is empty.\")\n",
        "                for file_name in os.listdir(label_folder_path):\n",
        "                    if file_name.endswith(\".wav\") or file_name.endswith(\".mp3\") or file_name.endswith(\".aac\") or file_name.endswith(\".flac\") or file_name.endswith(\".ogg\") or file_name.endswith(\".m4a\"):\n",
        "                        file_path = os.path.join(label_folder_path, file_name)\n",
        "                        print(f\"        Processing file: {file_path}\")\n",
        "                        try:\n",
        "                            mel_seq = extract_mel_sequence(file_path)\n",
        "                            X.append(mel_seq)\n",
        "                            Y.append(label_folder_name) # Append the actual bird label string\n",
        "                            found_files_count += 1\n",
        "                            found_labels_set.add(label_folder_name)\n",
        "                        except Exception as e:\n",
        "                            print(f\"        Error processing {file_name}: {e}\")\n",
        "                    else:\n",
        "                        print(f\"        Skipping non-audio file (unsupported extension or not audio): {file_name}\")\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(\"\\n--- Data Loading Summary ---\")\n",
        "print(f\"Total files successfully processed: {found_files_count}\")\n",
        "print(f\"Actual labels from processed files: {sorted(list(found_labels_set))}\")\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Number of samples:\", len(X))\n",
        "print(\"Number of classes:\", len(np.unique(Y)) if len(Y) > 0 else 0)\n",
        "print(\"Classes:\", np.unique(Y) if len(Y) > 0 else \"No classes found\")\n"
      ],
      "metadata": {
        "id": "swjG5130UZw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "480583db"
      },
      "source": [
        "### Next Steps:\n",
        "\n",
        "Now that the `FileNotFoundError` is resolved, please run all the cells in the notebook from the beginning, starting with the import statements and Google Drive mount, then proceeding through data loading, preprocessing, model definition, training, evaluation, and finally the prediction. This will ensure the entire workflow is executed correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfe14cdd"
      },
      "source": [
        "le = LabelEncoder()\n",
        "Y_encoded = le.fit_transform(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "712877d9"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, Y_encoded, test_size=0.2, random_state=42, stratify=Y_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcc0b153"
      },
      "source": [
        "# Define the CRNN model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv1D, MaxPooling1D, Bidirectional, LSTM,\n",
        "    Dense, Dropout, BatchNormalization\n",
        ")\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(64, 5, activation=\"relu\", padding=\"same\", input_shape=(300,128)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(2),\n",
        "\n",
        "    Conv1D(128, 5, activation=\"relu\", padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(2),\n",
        "\n",
        "    Bidirectional(LSTM(128, return_sequences=False)),\n",
        "\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(len(np.unique(Y_encoded)), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1029b797"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b38a07fd"
      },
      "source": [
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"CRNN Test Accuracy:\", acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcbd79a2"
      },
      "source": [
        "# Final prediction\n",
        "# --- FINAL PREDICTION BLOCK ---\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Using a different compatible MP3 file for prediction, as the previous one caused issues.\n",
        "test_file = '/content/XC983831 - Asian Koel - Eudynamys scolopaceus.wav' # You might need to adjust this path to your test file\n",
        "\n",
        "# Convert audio â†’ mel sequence (same function used in training)\n",
        "mel_seq = extract_mel_sequence(test_file)\n",
        "mel_seq = mel_seq.reshape(1, 300, 128)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(mel_seq)\n",
        "bird = le.inverse_transform([np.argmax(pred)])\n",
        "\n",
        "print(\"\\n================================\")\n",
        "print(\"ðŸ”¥ FINAL BIRD SOUND PREDICTION ðŸ”¥\")\n",
        "print(\"Predicted Bird:\", bird[0])\n",
        "print(\"================================\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDbAjbUp7Xrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}