{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOFvl0c5Xf+ZncU+FpqiP4v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuveljebakumar/fish/blob/main/cnn_and_lstm_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUuN8HCzr5j8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ytV18irtsN3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/all data set\"\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "DURATION = 3\n",
        "SAMPLES = SAMPLE_RATE * DURATION\n",
        "\n",
        "N_MELS = 128\n",
        "N_FFT = 1024\n",
        "HOP_LENGTH = 512"
      ],
      "metadata": {
        "id": "5P-P87gwsi6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(file_path):\n",
        "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, mono=True)\n",
        "    audio = librosa.util.normalize(audio)\n",
        "    return audio\n",
        "\n",
        "def split_audio(audio):\n",
        "    clips = []\n",
        "    for i in range(0, len(audio) - SAMPLES, SAMPLES):\n",
        "        clips.append(audio[i:i+SAMPLES])\n",
        "    return clips\n",
        "\n",
        "def extract_mel(audio_clip):\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=audio_clip,\n",
        "        sr=SAMPLE_RATE,\n",
        "        n_fft=N_FFT,\n",
        "        hop_length=HOP_LENGTH,\n",
        "        n_mels=N_MELS\n",
        "    )\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "    return mel_db\n"
      ],
      "metadata": {
        "id": "e0y_vb_7PG4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for category_folder in os.listdir(DATASET_PATH):\n",
        "    category_path = os.path.join(DATASET_PATH, category_folder)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing category: {category_folder}\") # Diagnostic print for main category (e.g., train/test)\n",
        "\n",
        "    for species_folder in os.listdir(category_path):\n",
        "        species_path = os.path.join(category_path, species_folder)\n",
        "        if not os.path.isdir(species_path):\n",
        "            continue\n",
        "\n",
        "        print(f\"  Processing bird species: {species_folder}\") # Diagnostic print for species\n",
        "\n",
        "        for audio_file_name in os.listdir(species_path):\n",
        "            file_path = os.path.join(species_path, audio_file_name)\n",
        "            # Skip if it's not a file (e.g., another subdirectory or a hidden file)\n",
        "            if not os.path.isfile(file_path):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                audio = load_audio(file_path)\n",
        "                clips = split_audio(audio)\n",
        "\n",
        "                for clip in clips:\n",
        "                    mel = extract_mel(clip)\n",
        "                    X.append(mel)\n",
        "                    y.append(species_folder) # Assign species_folder as the label\n",
        "                print(f\"    Processed file: {audio_file_name} - clips found: {len(clips)}\") # Diagnostic print for file\n",
        "            except Exception as e:\n",
        "                print(f\"    Error processing file {file_path}: {e}\") # Added error handling for file processing\n",
        "\n",
        "X = np.array(X)\n",
        "X = X[..., np.newaxis]  # add channel"
      ],
      "metadata": {
        "id": "w2_Cvm46sqWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples:\", len(X))\n",
        "print(\"Number of labels:\", len(y))\n",
        "print(\"First 10 labels:\", y[:10])\n"
      ],
      "metadata": {
        "id": "aLXkjnUptq1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "y_cat = to_categorical(y_encoded)\n"
      ],
      "metadata": {
        "id": "2N_1gaEKtt55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_cat, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "a1PW-h0wtwXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Bidirectional, GlobalAveragePooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First CNN block\n",
        "model.add(Conv2D(64, (3,3), activation='relu', input_shape=(N_MELS, X.shape[2], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Second CNN block\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Third CNN block\n",
        "model.add(Conv2D(256, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Reshape output for LSTM\n",
        "# Calculate the output shape dynamically for the reshape layer\n",
        "# The input to LSTM needs to be 3D (batch_size, timesteps, features)\n",
        "# Current model.output_shape before reshape: (None, height, width, channels)\n",
        "# We want (None, height, width * channels)\n",
        "reshape_dim_1 = model.output_shape[1] # height (timesteps)\n",
        "reshape_dim_2 = model.output_shape[2] * model.output_shape[3] # width * channels (features)\n",
        "model.add(Reshape((reshape_dim_1, reshape_dim_2)))\n",
        "\n",
        "# LSTM layer\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True))) # Added Bidirectional LSTM and return_sequences\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(LSTM(64)) # Added a second LSTM layer\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "qOKLDgbyt3o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=40,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n"
      ],
      "metadata": {
        "id": "Pazt1QRAt9CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", acc * 100)\n"
      ],
      "metadata": {
        "id": "rguIXZRdt_6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f241f7ab"
      },
      "source": [
        "def predict_bird_species(audio_file_path, model, encoder):\n",
        "    try:\n",
        "        # Load and preprocess the new audio file\n",
        "        audio = load_audio(audio_file_path)\n",
        "        clips = split_audio(audio)\n",
        "\n",
        "        if not clips:\n",
        "            print(f\"No valid audio clips found in {audio_file_path}\")\n",
        "            return None\n",
        "\n",
        "        mels = []\n",
        "        for clip in clips:\n",
        "            mel = extract_mel(clip)\n",
        "            mels.append(mel)\n",
        "\n",
        "        # Convert list of mels to numpy array and add channel dimension\n",
        "        X_new = np.array(mels)\n",
        "        X_new = X_new[..., np.newaxis]\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(X_new)\n",
        "\n",
        "        # Average predictions across all clips if multiple clips are present\n",
        "        # Or take the prediction for the single clip if only one\n",
        "        avg_prediction = np.mean(predictions, axis=0)\n",
        "\n",
        "        # Get the predicted class index\n",
        "        predicted_class_idx = np.argmax(avg_prediction)\n",
        "\n",
        "        # Decode the predicted class index back to the bird species name\n",
        "        predicted_species = encoder.inverse_transform([predicted_class_idx])\n",
        "\n",
        "        return predicted_species[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction for {audio_file_path}: {e}\")\n",
        "        return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d2bf66e"
      },
      "source": [
        "# Example usage with a file from the test dataset (replace with your new audio file path)\n",
        "new_audio_file ='/content/XC433062 - Common Tailorbird - Orthotomus sutorius.mp3'\n",
        "\n",
        "predicted_bird = predict_bird_species(new_audio_file, model, encoder)\n",
        "\n",
        "if predicted_bird:\n",
        "    print(f\"The predicted bird species is: {predicted_bird}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3336e574"
      },
      "source": [
        "print(\"Bird species in the dataset:\")\n",
        "for i, species in enumerate(encoder.classes_):\n",
        "    print(f\"{i+1}. {species}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}