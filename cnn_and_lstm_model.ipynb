{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7neD/uE5bgQTUsmwqBM84",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuveljebakumar/fish/blob/main/cnn_and_lstm_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUuN8HCzr5j8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ytV18irtsN3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/all data set\"\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "DURATION = 3\n",
        "SAMPLES = SAMPLE_RATE * DURATION\n",
        "\n",
        "N_MELS = 128\n",
        "N_FFT = 1024\n",
        "HOP_LENGTH = 512"
      ],
      "metadata": {
        "id": "5P-P87gwsi6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(file_path):\n",
        "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, mono=True)\n",
        "    audio = librosa.util.normalize(audio)\n",
        "    return audio\n",
        "\n",
        "def split_audio(audio):\n",
        "    clips = []\n",
        "    for i in range(0, len(audio) - SAMPLES, SAMPLES):\n",
        "        clips.append(audio[i:i+SAMPLES])\n",
        "    return clips\n",
        "\n",
        "def extract_mel(audio_clip):\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=audio_clip,\n",
        "        sr=SAMPLE_RATE,\n",
        "        n_fft=N_FFT,\n",
        "        hop_length=HOP_LENGTH,\n",
        "        n_mels=N_MELS\n",
        "    )\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "    return mel_db\n"
      ],
      "metadata": {
        "id": "e0y_vb_7PG4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for category_folder in os.listdir(DATASET_PATH):\n",
        "    category_path = os.path.join(DATASET_PATH, category_folder)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing category: {category_folder}\") # Diagnostic print for main category (e.g., train/test)\n",
        "\n",
        "    for species_folder in os.listdir(category_path):\n",
        "        species_path = os.path.join(category_path, species_folder)\n",
        "        if not os.path.isdir(species_path):\n",
        "            continue\n",
        "\n",
        "        print(f\"  Processing bird species: {species_folder}\") # Diagnostic print for species\n",
        "\n",
        "        for audio_file_name in os.listdir(species_path):\n",
        "            file_path = os.path.join(species_path, audio_file_name)\n",
        "            # Skip if it's not a file (e.g., another subdirectory or a hidden file)\n",
        "            if not os.path.isfile(file_path):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                audio = load_audio(file_path)\n",
        "                clips = split_audio(audio)\n",
        "\n",
        "                for clip in clips:\n",
        "                    mel = extract_mel(clip)\n",
        "                    X.append(mel)\n",
        "                    y.append(species_folder) # Assign species_folder as the label\n",
        "                print(f\"    Processed file: {audio_file_name} - clips found: {len(clips)}\") # Diagnostic print for file\n",
        "            except Exception as e:\n",
        "                print(f\"    Error processing file {file_path}: {e}\") # Added error handling for file processing\n",
        "\n",
        "X = np.array(X)\n",
        "X = X[..., np.newaxis]  # add channel"
      ],
      "metadata": {
        "id": "w2_Cvm46sqWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples:\", len(X))\n",
        "print(\"Number of labels:\", len(y))\n",
        "print(\"First 10 labels:\", y[:10])\n"
      ],
      "metadata": {
        "id": "aLXkjnUptq1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "y_cat = to_categorical(y_encoded)\n"
      ],
      "metadata": {
        "id": "2N_1gaEKtt55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_cat, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "a1PW-h0wtwXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Bidirectional, GlobalAveragePooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First CNN block\n",
        "model.add(Conv2D(64, (3,3), activation='relu', input_shape=(N_MELS, X.shape[2], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Second CNN block\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Third CNN block\n",
        "model.add(Conv2D(256, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Reshape output for LSTM\n",
        "# Calculate the output shape dynamically for the reshape layer\n",
        "# The input to LSTM needs to be 3D (batch_size, timesteps, features)\n",
        "# Current model.output_shape before reshape: (None, height, width, channels)\n",
        "# We want (None, height, width * channels)\n",
        "reshape_dim_1 = model.output_shape[1] # height (timesteps)\n",
        "reshape_dim_2 = model.output_shape[2] * model.output_shape[3] # width * channels (features)\n",
        "model.add(Reshape((reshape_dim_1, reshape_dim_2)))\n",
        "\n",
        "# LSTM layer (implementation=2 for TFLite compatibility)\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True, implementation=2))) # Changed implementation to 2\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(LSTM(64, implementation=2)) # Changed implementation to 2\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qOKLDgbyt3o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=40,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n"
      ],
      "metadata": {
        "id": "Pazt1QRAt9CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", acc * 100)\n"
      ],
      "metadata": {
        "id": "rguIXZRdt_6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f241f7ab"
      },
      "source": [
        "def predict_bird_species(audio_file_path, model, encoder):\n",
        "    try:\n",
        "        # Load and preprocess the new audio file\n",
        "        audio = load_audio(audio_file_path)\n",
        "        clips = split_audio(audio)\n",
        "\n",
        "        if not clips:\n",
        "            print(f\"No valid audio clips found in {audio_file_path}\")\n",
        "            return None\n",
        "\n",
        "        mels = []\n",
        "        for clip in clips:\n",
        "            mel = extract_mel(clip)\n",
        "            mels.append(mel)\n",
        "\n",
        "        # Convert list of mels to numpy array and add channel dimension\n",
        "        X_new = np.array(mels)\n",
        "        X_new = X_new[..., np.newaxis]\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(X_new)\n",
        "\n",
        "        # Average predictions across all clips if multiple clips are present\n",
        "        # Or take the prediction for the single clip if only one\n",
        "        avg_prediction = np.mean(predictions, axis=0)\n",
        "\n",
        "        # Get the predicted class index\n",
        "        predicted_class_idx = np.argmax(avg_prediction)\n",
        "\n",
        "        # Decode the predicted class index back to the bird species name\n",
        "        predicted_species = encoder.inverse_transform([predicted_class_idx])\n",
        "\n",
        "        return predicted_species[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction for {audio_file_path}: {e}\")\n",
        "        return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d2bf66e"
      },
      "source": [
        "# Example usage with a file from the test dataset (replace with your new audio file path)\n",
        "new_audio_file ='/content/WhatsApp Audio 2026-01-12 at 11.11.03 PM (2).mp4'\n",
        "\n",
        "predicted_bird = predict_bird_species(new_audio_file, model, encoder)\n",
        "\n",
        "if predicted_bird:\n",
        "    print(f\"The predicted bird species is: {predicted_bird}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3336e574"
      },
      "source": [
        "print(\"Bird species in the dataset:\")\n",
        "for i, species in enumerate(encoder.classes_):\n",
        "    print(f\"{i+1}. {species}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"üöÄ Starting conversion process...\")\n",
        "\n",
        "# 1. Check if model exists in memory\n",
        "if 'model' not in locals() and 'model' not in globals():\n",
        "    print(\"‚ùå Error: The variable 'model' is not found.\")\n",
        "    print(\"   Please run your training cell (the one with model.fit) again first!\")\n",
        "else:\n",
        "    try:\n",
        "        # ==========================================\n",
        "        # STEP 1: Save the Master Backup (.h5)\n",
        "        # ==========================================\n",
        "        model.save('bird_model_master.h5')\n",
        "        print(\"‚úÖ Backup model (.h5) saved.\")\n",
        "\n",
        "        # ==========================================\n",
        "        # STEP 2: Configure Converter for LSTM/Bidirectional\n",
        "        # ==========================================\n",
        "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "        # CRITICAL FIX 1: Enable TensorFlow Ops and Custom Ops\n",
        "        # This allows the Pi to run complex layers like LSTM/Bidirectional\n",
        "        converter.target_spec.supported_ops = [\n",
        "            tf.lite.OpsSet.TFLITE_BUILTINS, # Standard Lite ops\n",
        "            tf.lite.OpsSet.SELECT_TF_OPS    # Full TensorFlow ops (needed for your layers)\n",
        "        ]\n",
        "        converter.allow_custom_ops = True # Explicitly allow custom operations\n",
        "\n",
        "        # CRITICAL FIX 2: Relax optimization constraints\n",
        "        # Sometimes 'DEFAULT' optimization breaks complex RNNs.\n",
        "        # We will try standard conversion first.\n",
        "        converter._experimental_lower_tensor_list_ops = False\n",
        "\n",
        "        print(\"‚è≥ Converting model to TFLite... (This may take 1-2 minutes)\")\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        # ==========================================\n",
        "        # STEP 3: Save and Download\n",
        "        # ==========================================\n",
        "        tflite_filename = 'bird_model_fixed.tflite'\n",
        "        with open(tflite_filename, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        print(f\"‚úÖ Success! Converted model saved as '{tflite_filename}'\")\n",
        "        print(f\"üìè Model size: {len(tflite_model) / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "        # Automatic Download\n",
        "        print(\"‚¨áÔ∏è Downloading to your computer...\")\n",
        "        files.download(tflite_filename)\n",
        "        files.download('bird_model_master.h5')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\n‚ùå CONVERSION FAILED!\")\n",
        "        print(f\"Error details: {str(e)}\")\n",
        "        print(\"\\nPossible fix: If the error mentions 'static shape', re-build your model with a fixed input_shape.\")"
      ],
      "metadata": {
        "id": "r1Bz_5PdzVQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OMJRf-pYI34-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}