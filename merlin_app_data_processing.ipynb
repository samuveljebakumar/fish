{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP9VJ1tKvrCfu20zWkB3U50",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuveljebakumar/fish/blob/main/merlin_app_data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moVKNGJqNyT4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9Rx1hAdPN735"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/all data set\"\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "DURATION = 3\n",
        "SAMPLES = SAMPLE_RATE * DURATION\n",
        "\n",
        "N_MELS = 128\n",
        "N_FFT = 1024\n",
        "HOP_LENGTH = 512\n"
      ],
      "metadata": {
        "id": "YCHP6Kf0N9O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(file_path):\n",
        "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, mono=True)\n",
        "    audio = librosa.util.normalize(audio)\n",
        "    return audio\n",
        "\n",
        "def split_audio(audio):\n",
        "    clips = []\n",
        "    for i in range(0, len(audio) - SAMPLES, SAMPLES):\n",
        "        clips.append(audio[i:i+SAMPLES])\n",
        "    return clips\n",
        "\n",
        "def extract_mel(audio_clip):\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=audio_clip,\n",
        "        sr=SAMPLE_RATE,\n",
        "        n_fft=N_FFT,\n",
        "        hop_length=HOP_LENGTH,\n",
        "        n_mels=N_MELS\n",
        "    )\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "    return mel_db\n"
      ],
      "metadata": {
        "id": "e0y_vb_7PG4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for category_folder in os.listdir(DATASET_PATH):\n",
        "    category_path = os.path.join(DATASET_PATH, category_folder)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing category: {category_folder}\") # Diagnostic print for main category (e.g., train/test)\n",
        "\n",
        "    for species_folder in os.listdir(category_path):\n",
        "        species_path = os.path.join(category_path, species_folder)\n",
        "        if not os.path.isdir(species_path):\n",
        "            continue\n",
        "\n",
        "        print(f\"  Processing bird species: {species_folder}\") # Diagnostic print for species\n",
        "\n",
        "        for audio_file_name in os.listdir(species_path):\n",
        "            file_path = os.path.join(species_path, audio_file_name)\n",
        "            # Skip if it's not a file (e.g., another subdirectory or a hidden file)\n",
        "            if not os.path.isfile(file_path):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                audio = load_audio(file_path)\n",
        "                clips = split_audio(audio)\n",
        "\n",
        "                for clip in clips:\n",
        "                    mel = extract_mel(clip)\n",
        "                    X.append(mel)\n",
        "                    y.append(species_folder) # Assign species_folder as the label\n",
        "                print(f\"    Processed file: {audio_file_name} - clips found: {len(clips)}\") # Diagnostic print for file\n",
        "            except Exception as e:\n",
        "                print(f\"    Error processing file {file_path}: {e}\") # Added error handling for file processing\n",
        "\n",
        "X = np.array(X)\n",
        "X = X[..., np.newaxis]  # add channel"
      ],
      "metadata": {
        "id": "HVrHLij6PNm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples:\", len(X))\n",
        "print(\"Number of labels:\", len(y))\n",
        "print(\"First 10 labels:\", y[:10])\n"
      ],
      "metadata": {
        "id": "1ccucvdhQwYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "y_cat = to_categorical(y_encoded)\n"
      ],
      "metadata": {
        "id": "jbqw5ozYPcrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_cat, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "hrNC-nj_POUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation='relu',\n",
        "                 input_shape=(128, X.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Reshape((model.output_shape[1],\n",
        "                    model.output_shape[2] * model.output_shape[3])))\n",
        "\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "BbrHlMI1R3hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n"
      ],
      "metadata": {
        "id": "ulj1YY1-R7PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", acc * 100)\n"
      ],
      "metadata": {
        "id": "293kS4TMSslA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "227021cd"
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Bidirectional, GlobalAveragePooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First CNN block\n",
        "model.add(Conv2D(64, (3,3), activation='relu', input_shape=(N_MELS, X.shape[2], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Second CNN block\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Third CNN block\n",
        "model.add(Conv2D(256, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Reshape output for LSTM\n",
        "# Calculate the output shape dynamically for the reshape layer\n",
        "# The input to LSTM needs to be 3D (batch_size, timesteps, features)\n",
        "# Current model.output_shape before reshape: (None, height, width, channels)\n",
        "# We want (None, height, width * channels)\n",
        "reshape_dim_1 = model.output_shape[1] # height (timesteps)\n",
        "reshape_dim_2 = model.output_shape[2] * model.output_shape[3] # width * channels (features)\n",
        "model.add(Reshape((reshape_dim_1, reshape_dim_2)))\n",
        "\n",
        "# LSTM layer\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True))) # Added Bidirectional LSTM and return_sequences\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(LSTM(64)) # Added a second LSTM layer\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5940ac9a"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}